{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29b3e5d5350>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(1, 1, self.hidden_dim),\n",
    "                torch.zeros(1, 1, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from keras.utils import to_categorical\n",
    "import json\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"debugging/atis.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "train_dev_sents = data[\"train_sents\"] # list of lists\n",
    "train_dev_labels = data[\"train_labels\"] # list of lists\n",
    "num_train = math.floor(0.8 * len(train_dev_sents))\n",
    "train_sents = train_dev_sents[:num_train]\n",
    "train_labels = train_dev_labels[:num_train]\n",
    "dev_sents = train_dev_sents[num_train:]\n",
    "dev_labels = train_dev_labels[num_train:]\n",
    "test_sents = data[\"test_sents\"]\n",
    "test_labels = data[\"test_labels\"]\n",
    "word_to_id = data[\"vocab\"]\n",
    "label_to_id = data[\"label_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[232,\n",
       " 542,\n",
       " 502,\n",
       " 196,\n",
       " 208,\n",
       " 77,\n",
       " 62,\n",
       " 10,\n",
       " 35,\n",
       " 40,\n",
       " 58,\n",
       " 234,\n",
       " 137,\n",
       " 62,\n",
       " 11,\n",
       " 234,\n",
       " 481,\n",
       " 321]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dev_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_TOKEN = \"<UNK>\"\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "VOCAB_SIZE = len(word_to_id)\n",
    "NUM_LABELS = len(label_to_id)\n",
    "EMBEDDING_SIZE = 50\n",
    "HIDDEN_SIZE=50\n",
    "MAX_LENGTH=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "572\n",
      "126\n"
     ]
    }
   ],
   "source": [
    "print(word_to_id[UNK_TOKEN])\n",
    "print(word_to_id[PAD_TOKEN])\n",
    "print(label_to_id[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "want\n",
      "to\n",
      "fly\n",
      "from\n",
      "boston\n",
      "at\n",
      "DIGITDIGITDIGIT\n",
      "am\n",
      "and\n",
      "arrive\n",
      "in\n",
      "denver\n",
      "at\n",
      "DIGITDIGITDIGITDIGIT\n",
      "in\n",
      "the\n",
      "morning\n"
     ]
    }
   ],
   "source": [
    "id_to_word = {word:id_ for id_, word in word_to_id.items()}\n",
    "id_to_label = {label:id_ for id_, label in label_to_id.items()}\n",
    "\n",
    "for i in train_dev_sents[0]: print(id_to_word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq): #, to_ix):\n",
    "    idxs = seq #[to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EMBEDDING_DIM = 25\n",
    "HIDDEN_DIM = 25\n",
    "\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_id), len(label_to_id))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:25<00:00, 221.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8641, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:23<00:00, 216.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3848, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:23<00:00, 212.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2673, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:30<00:00, 163.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2068, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:26<00:00, 188.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1692, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:28<00:00, 177.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1437, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:29<00:00, 168.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1253, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:25<00:00, 195.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1105, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:24<00:00, 191.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0992, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:25<00:00, 192.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0893, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:24<00:00, 203.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0816, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:23<00:00, 211.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0752, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:27<00:00, 183.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0695, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:27<00:00, 184.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0646, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:25<00:00, 197.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0602, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:28<00:00, 172.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0564, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:25<00:00, 193.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0530, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:29<00:00, 168.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0500, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:28<00:00, 174.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0477, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:25<00:00, 194.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0457, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:23<00:00, 207.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0444, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:23<00:00, 209.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0408, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:34<00:00, 145.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0389, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:33<00:00, 149.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0365, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4978/4978 [00:32<00:00, 157.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0345, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "#with torch.no_grad():\n",
    "#    inputs = prepare_sequence(training_data[0][0])#, word_to_ix)\n",
    "#    tag_scores = model(inputs)\n",
    "#    print(tag_scores)\n",
    "n_total = len(train_dev_sents)\n",
    "for epoch in range(25):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    accum_loss = 0\n",
    "    for sentence, tags in tqdm(zip(train_dev_sents, train_dev_labels), total=n_total):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence)#, word_to_ix)\n",
    "        targets = prepare_sequence(tags)#, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        \n",
    "        accum_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(accum_loss / n_total)\n",
    "\n",
    "# See what the scores are after training\n",
    "#with torch.no_grad():\n",
    "#    inputs = prepare_sequence(training_data[0][0])#, word_to_ix)\n",
    "#    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "#    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After 5 epochs: tensor(0.1692, grad_fn=<DivBackward0>)\n",
    "# After 25 epochs: tensor(0.0345, grad_fn=<DivBackward0>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9395520765383779\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for sentence, tags in zip(test_sents, test_labels):\n",
    "    sentence_in = prepare_sequence(sentence)#, word_to_ix)\n",
    "    targets = prepare_sequence(tags)#, tag_to_ix)\n",
    "    tag_scores = model(sentence_in)\n",
    "    correct += (tag_scores.argmax(-1) == targets).sum()\n",
    "    total += len(targets)\n",
    "    \n",
    "print(float(correct) / float(total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.9395520765383779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_meshgrid(*args):\n",
    "    \"\"\"\n",
    "    Creates a meshgrid from possibly many\n",
    "    elements (instead of only 2).\n",
    "    Returns a nd tensor with as many dimensions\n",
    "    as there are arguments\n",
    "    \"\"\"\n",
    "    args = list(args)\n",
    "    template = [1 for _ in args]\n",
    "    for i in range(len(args)):\n",
    "        n = args[i].shape[0]\n",
    "        template_copy = template.copy()\n",
    "        template_copy[i] = n\n",
    "        args[i] = args[i].view(*template_copy)\n",
    "        # there will be some broadcast magic going on\n",
    "    return tuple(args)\n",
    "\n",
    "def flip(tensor, dims):\n",
    "    \"\"\"\n",
    "    This function should be in native PyTorch hopefully after 0.4\n",
    "    :param tensor:\n",
    "    :param dims:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not isinstance(dims, (tuple, list)):\n",
    "        dims = [dims]\n",
    "    indices = [torch.arange(tensor.shape[dim] - 1, -1, -1,\n",
    "                                        dtype=torch.long, device=\"cuda\") for dim in dims]\n",
    "    multi_indices = multi_meshgrid(*indices)\n",
    "    final_indices = [slice(i) for i in tensor.shape]\n",
    "    for i, dim in enumerate(dims):\n",
    "        final_indices[dim] = multi_indices[i]\n",
    "    flipped = tensor[final_indices]\n",
    "    return flipped\n",
    "\n",
    "def stripe(a, left_top=True): # NON-BATCH version\n",
    "    \"\"\"\n",
    "    Get a diagonal stripe of a matrix m x n, where n > m\n",
    "    this implementation also takes into account batched matrices,\n",
    "    so the stripe is calculated over a batch x for a matrix of size[x, m, n]\n",
    "    left_top: whether stripe goes from left top to right bottom \n",
    "    (otherwise stripe from right top to left bottom is returned)\n",
    "    \"\"\"\n",
    "    if not left_top:\n",
    "        a = flip(a, -1)\n",
    "    head, i, j = a.size()\n",
    "\n",
    "    assert i <= j\n",
    "    head_s, k, l = a.stride()\n",
    "    # left top to right bottom\n",
    "    new_shape = (head, i, i)\n",
    "    steps = (head_s, k+l, l)\n",
    "    result = torch.as_strided(a, new_shape, steps)\n",
    "    if not left_top:\n",
    "        result = flip(result, -1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout, n_head): # size == d_model\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.size = size\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.rel_pos_embeddings = nn.Embedding((MAX_LENGTH*2)-1, size//n_head)#, padding_idx=PAD)\n",
    "        assert self.rel_pos_embeddings.weight.requires_grad # TODO: necessary to set?\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        length = x.size(-2)\n",
    "        pos_indices = torch.tensor(range(MAX_LENGTH - length, MAX_LENGTH + length - 1), dtype=torch.long)\n",
    "        #np.arange(MAX_LENGTH - length, MAX_LENGTH + length - 1)\n",
    "        position = self.rel_pos_embeddings(pos_indices)\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, position))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "\n",
    "attn_lists_0 = [[] for _ in range(10)]\n",
    "attn_lists_1 = [[] for _ in range(10)]\n",
    "attn_lists_2 = [[] for _ in range(10)]\n",
    "attn_lists_3 = [[] for _ in range(10)]\n",
    "\n",
    "def attention(query, key, value, rel_pos_vecs, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    # query/key/value.shape: head x position x hidden_size\n",
    "    d_k = query.size(-1)\n",
    "    # head x position x hidden_size *matmul* head x hidden_size x position => head x query_position x key_position\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        \n",
    "    pos_query = query # TODO: make additional mapping for pos_query (as for query/key/value) ...\n",
    "    # ... or for the position embeddding so that it depends on the head\n",
    "    \n",
    "    # rel_pos_vecs: position encodings for dot product attention\n",
    "    # broadcastable/head x positions_times_2-1  x hidden_size\n",
    "    assert rel_pos_vecs.size(-2) == query.size(-2) * 2 - 1 # TODO: was there a wrong size in the original implementation?\n",
    "    assert rel_pos_vecs.size(-3) == 1 or rel_pos_vecs.size(-3) == query.size(0) # first dimension ...\n",
    "    #... of relative position representation broadcastable (=same) for each head, or different for each head\n",
    "    \n",
    "    # head x position x hidden_size *matmul* broadcastable/head x hidden_size x relative_positions\n",
    "    # => head x query_position x relative_positions\n",
    "    # Here, relative positions are not yet shifted -> relative_positions = 2*key_positions-1\n",
    "    rel_pos_scores = torch.matmul(pos_query, rel_pos_vecs.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    # get (inverse-)diagonal stripe (from right top to left bottom)\n",
    "    rel_pos_scores = stripe(rel_pos_scores, left_top=False)\n",
    "    # Now relative positions are shifted w.r.t. the query.\n",
    "    # Resulting shape: heads x query_positions x key_positions\n",
    "    assert rel_pos_scores.size(-1) == rel_pos_scores.size(-2)\n",
    "    assert rel_pos_scores.size(-1) == query.size(-2)\n",
    "    \n",
    "    position_distribution = F.softmax(rel_pos_scores, dim = -1)\n",
    "    \n",
    "    scores = scores + rel_pos_scores\n",
    "    p_attn = F.softmax(scores, dim = -1) # for each query normalize over key positions\n",
    "    \n",
    "    if query.size(1)> 2:\n",
    "        for i in range(min(10, query.size(1))):\n",
    "            attn_lists_0[i].append(float(position_distribution[0,2,i])) # head 0, query position 2, i-th key position\n",
    "            attn_lists_1[i].append(float(position_distribution[1,2,i])) # head 1, query position 2, i-th key position\n",
    "            attn_lists_2[i].append(float(position_distribution[2,2,i])) # head 2, query position 2, i-th key position\n",
    "            attn_lists_3[i].append(float(position_distribution[3,2,i])) # head 3, query position 2, i-th key position\n",
    "\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, position):\n",
    "        \"Implements Figure 2\"\n",
    "        # TODO: what type is query/key/value? => whole sequence of input embeddings.\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(-1, self.h, self.d_k).transpose(0, 1)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # head x position x hidden_size\n",
    "        position = position.unsqueeze(0)\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, position, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(0, 1).contiguous() \\\n",
    "             .view(-1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=MAX_LENGTH):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        \n",
    "        print(position)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        print(div_term)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        #pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:x.size(0)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tagger(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, src_embed, hidden_size, nb_tags):\n",
    "        super(Tagger, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.src_embed = src_embed\n",
    "        self.hidden_to_tag = nn.Linear(hidden_size, nb_tags)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        tag_space = self.hidden_to_tag(self.encode(src))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)# TODO: check dim (-1 better?)\n",
    "        return tag_scores\n",
    "    \n",
    "    def encode(self, src):\n",
    "        return self.encoder(self.src_embed(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model(vocab_size, nb_tags, N=2, \n",
    "               d_model=40, d_ff=25, h=4, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = Tagger(Encoder(EncoderLayer(d_model, attn, ff, dropout, h), N),\n",
    "        nn.Sequential(Embeddings(d_model, vocab_size), position),\n",
    "        hidden_size=d_model, nb_tags=nb_tags)\n",
    "    \n",
    "    # This was important from their codsrc_vocabe. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.],\n",
      "        [ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.],\n",
      "        [11.],\n",
      "        [12.],\n",
      "        [13.],\n",
      "        [14.],\n",
      "        [15.],\n",
      "        [16.],\n",
      "        [17.],\n",
      "        [18.],\n",
      "        [19.],\n",
      "        [20.],\n",
      "        [21.],\n",
      "        [22.],\n",
      "        [23.],\n",
      "        [24.],\n",
      "        [25.],\n",
      "        [26.],\n",
      "        [27.],\n",
      "        [28.],\n",
      "        [29.],\n",
      "        [30.],\n",
      "        [31.],\n",
      "        [32.],\n",
      "        [33.],\n",
      "        [34.],\n",
      "        [35.],\n",
      "        [36.],\n",
      "        [37.],\n",
      "        [38.],\n",
      "        [39.],\n",
      "        [40.],\n",
      "        [41.],\n",
      "        [42.],\n",
      "        [43.],\n",
      "        [44.],\n",
      "        [45.],\n",
      "        [46.],\n",
      "        [47.],\n",
      "        [48.],\n",
      "        [49.],\n",
      "        [50.],\n",
      "        [51.],\n",
      "        [52.],\n",
      "        [53.],\n",
      "        [54.],\n",
      "        [55.],\n",
      "        [56.],\n",
      "        [57.],\n",
      "        [58.],\n",
      "        [59.],\n",
      "        [60.],\n",
      "        [61.],\n",
      "        [62.],\n",
      "        [63.],\n",
      "        [64.],\n",
      "        [65.],\n",
      "        [66.],\n",
      "        [67.],\n",
      "        [68.],\n",
      "        [69.],\n",
      "        [70.],\n",
      "        [71.],\n",
      "        [72.],\n",
      "        [73.],\n",
      "        [74.],\n",
      "        [75.],\n",
      "        [76.],\n",
      "        [77.],\n",
      "        [78.],\n",
      "        [79.],\n",
      "        [80.],\n",
      "        [81.],\n",
      "        [82.],\n",
      "        [83.],\n",
      "        [84.],\n",
      "        [85.],\n",
      "        [86.],\n",
      "        [87.],\n",
      "        [88.],\n",
      "        [89.],\n",
      "        [90.],\n",
      "        [91.],\n",
      "        [92.],\n",
      "        [93.],\n",
      "        [94.],\n",
      "        [95.],\n",
      "        [96.],\n",
      "        [97.],\n",
      "        [98.],\n",
      "        [99.]])\n",
      "tensor([1.0000, 0.6310, 0.3981, 0.2512, 0.1585, 0.1000, 0.0631, 0.0398, 0.0251,\n",
      "        0.0158, 0.0100, 0.0063, 0.0040, 0.0025, 0.0016, 0.0010, 0.0006, 0.0004,\n",
      "        0.0003, 0.0002])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model = make_model(len(word_to_id), len(label_to_id))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53cfea31ba24892afff288126f0a458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3975, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313e31cd3951486bbc0449066556f9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1232, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92126242bdb4dc19d584842a44514c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0822, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aeed89ecc5643d7b539e446dc2b094c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0614, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f226ac69e5d44cd9fcb667fc8b7ae47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0525, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0eb7c4b949944ddb625ba2aada80000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0463, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653b51baae2c47cfb43cdbc1c7dc1e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0389, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1f7451bbc94f30af8c28678392937a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0356, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aca9779b87d43dca2de51540941ec0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0301, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d959a59facb241f48e41184f28ce3060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0268, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2732df116c9b4b9b887274486bafb35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0281, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc273bd98ed94d57ae73e42565db142a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0271, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918bb18631314beea02003221390fc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0215, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d387f56d33f4d35b5dab6803de1fd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0198, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31d3b2aec5d403092be1d325f525c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0189, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f0a6e7b2f74537a881b7fef12fafa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-227-c4a1e7ee6485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Step 3. Run our forward pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtag_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Step 4. Compute the loss, gradients, and update the parameters by\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-223-e64761ef9070>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;34m\"Take in and process masked src and target sequences.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtag_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_to_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mtag_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# TODO: check dim (-1 better?)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtag_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "n_total = len(train_dev_sents)\n",
    "for epoch in range(25):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    accum_loss = 0\n",
    "    for sentence, tags in tqdm(zip(train_dev_sents, train_dev_labels), total=n_total):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence)#, word_to_ix)\n",
    "        targets = prepare_sequence(tags)#, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        accum_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(accum_loss / n_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After 5 epochs: tensor(0.1251, grad_fn=<DivBackward0>)\n",
    "# After 25 epochs: tensor(0.0679, grad_fn=<DivBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09721837500101903 154078 14979.21278340701\n",
      "0.1144624073281614 154078 17636.138796308453\n",
      "0.09581338038828995 154078 14762.73402346694\n",
      "0.11515539229853884 151872 17488.87973916369\n",
      "0.1059915970283634 149130 15806.526864839834\n",
      "0.0900451749685293 144498 13011.347692602547\n",
      "0.09161436097718885 138706 12707.461553701956\n",
      "0.08242612621788327 128454 10587.965617191978\n",
      "0.07910792859256256 114408 9050.579894417897\n",
      "0.07097024992136645 99054 7029.887135711033\n",
      "\n",
      "0.08764652787088788 154078 13504.401721290662\n",
      "0.13233445865175836 154078 20389.828720145626\n",
      "0.09547461510009381 154078 14710.537745392254\n",
      "0.11966644457067346 151872 18173.98226983732\n",
      "0.09750429591727496 149130 14540.815650143213\n",
      "0.09205421277205672 144498 13301.649637136652\n",
      "0.08291040433140828 138706 11500.170543192316\n",
      "0.08322518384568715 128454 10690.607765713898\n",
      "0.07520340516405925 114408 8603.871178009691\n",
      "0.0739175047087922 99054 7321.824511424702\n",
      "\n",
      "0.09460808185294364 154078 14577.02403573785\n",
      "0.14654967788508277 154078 22580.081269177783\n",
      "0.07899321694605196 154078 12171.116880613794\n",
      "0.14098154568359345 151872 21411.149306058705\n",
      "0.09892667044873667 149130 14752.934364020099\n",
      "0.08321052128410257 144498 12023.753904510253\n",
      "0.07723330084397814 138706 10712.722226864833\n",
      "0.07304525426130513 128454 9382.95509088169\n",
      "0.07683851846741863 114408 8790.94122082043\n",
      "0.07420521507825763 99054 7350.323374361731\n",
      "\n",
      "0.0899937544384598 154078 13866.057696369011\n",
      "0.1307359798296534 154078 20143.538300193337\n",
      "0.1035132258258145 154078 15949.110808789846\n",
      "0.1375569197487649 151872 20891.044516084425\n",
      "0.08772608847769349 149130 13082.59157467843\n",
      "0.086119702413781 144498 12444.124759386526\n",
      "0.08433876583182268 138706 11698.292853468796\n",
      "0.07379673425512415 128454 9479.485702007718\n",
      "0.07420201015467 114408 8489.303577775485\n",
      "0.07256988082446071 99054 7188.336975186132\n",
      "\n",
      "0.09236668479082759 154078 14231.674059201134\n",
      "0.13102063092366398 154078 20187.3967714563\n",
      "0.09344860956506255 154078 14398.374864565709\n",
      "0.12834007557539268 151872 19491.263957786035\n",
      "0.09753716296801714 149130 14545.717113420395\n",
      "0.08785740285961739 144498 12695.218998408995\n",
      "0.08402420799609948 138706 11654.661794306976\n",
      "0.07812332464499992 128454 10035.25354394882\n",
      "0.0763379655946776 114408 8733.673967755876\n",
      "0.07291571263321925 99054 7222.5929991709\n"
     ]
    }
   ],
   "source": [
    "for l in attn_lists_0:\n",
    "    print(sum(l)/len(l), len(l), sum(l) )\n",
    "print()\n",
    "for l in attn_lists_1:\n",
    "    print(sum(l)/len(l), len(l), sum(l) )\n",
    "print()\n",
    "for l in attn_lists_2:\n",
    "    print(sum(l)/len(l), len(l), sum(l) )\n",
    "print()\n",
    "for l in attn_lists_3:\n",
    "    print(sum(l)/len(l), len(l), sum(l) )\n",
    "    \n",
    "print()\n",
    "for l in zip(attn_lists_0, attn_lists_1, attn_lists_2, attn_lists_3):\n",
    "    s = (sum(l[0]) + sum(l[1]) + sum(l[2]) + sum(l[3]))/4\n",
    "    assert len(l[0]) == len(l[1])\n",
    "    print(s/len(l[1]), len(l[1]), s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8885627310284845\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for sentence, tags in zip(test_sents, test_labels):\n",
    "    sentence_in = prepare_sequence(sentence)#, word_to_ix)\n",
    "    targets = prepare_sequence(tags)#, tag_to_ix)\n",
    "    tag_scores = model(sentence_in)\n",
    "    correct += (tag_scores.argmax(-1) == targets).sum()\n",
    "    total += len(targets)\n",
    "    \n",
    "print(float(correct) / float(total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb33dcd4076c4f9398cfd0eab34f0167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.9193, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bf4861a13d42be9b1cd6ab98862232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.5314, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8e711132b84251bd46642d267eb006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.4500, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31e61ffdb8542af99ff9e5dac81163d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.4125, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9cbbe24c9f4ef0805b3f1d152e4511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3901, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f215275f957f4643aeacb25f55ecd341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3748, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7107ecf30524b68bedd63d1715023c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3636, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3cdb4adc764b08a4b9ef2ed5e51361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3550, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba1b461640c416ebf2074afa872d460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3482, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a399f25bdacc484e8be4e9ce8d3701f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3427, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac26a2315ca42caae3ffebdfec0f398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3382, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955de64db7c94b298327e74c3e46ccf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3344, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b2cc816945409ea5b850e7d9b9b2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3311, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b46ac9ac3a4c01a3e13c26b8518dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3284, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49bb72e5d654c2690517b2a3fd3676f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3260, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182a803cdd8243869a7c51a12ec2a9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3239, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d57aa07b458461ab9a7e23b3f911d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3220, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c14ac968504a0db14dcf12877692a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3204, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcd8db3f03a4fb9803d6149311d6622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3190, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e7a3ddb4bf432eb70201c332ee3d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3178, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e64e57b860c4c74b8ada9a848b0cd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3166, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b777428aa1043e9a89168f1372fb9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3156, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15956c1d65524754bd6ce08dd313d664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3147, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a8947c10ae4e409ba9c725c96751b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3139, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb79c19912804285abec3cb13e0f1473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.3132, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class BasicTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, tagset_size):\n",
    "        super(BasicTagger, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.embedding2tag = nn.Linear(embedding_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        tag_space = self.embedding2tag(embeds)\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n",
    "\n",
    "basic_model = BasicTagger(EMBEDDING_DIM, len(word_to_id), len(label_to_id))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(basic_model.parameters(), lr=0.1)\n",
    "\n",
    "n_total = len(train_dev_sents)\n",
    "for epoch in range(25):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    accum_loss = 0\n",
    "    for sentence, tags in tqdm(zip(train_dev_sents, train_dev_labels), total=n_total):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        basic_model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence)#, word_to_ix)\n",
    "        targets = prepare_sequence(tags)#, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = basic_model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        \n",
    "        accum_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(accum_loss / n_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8413785605566427\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for sentence, tags in zip(test_sents, test_labels):\n",
    "    sentence_in = prepare_sequence(sentence)#, word_to_ix)\n",
    "    targets = prepare_sequence(tags)#, tag_to_ix)\n",
    "    tag_scores = basic_model(sentence_in)\n",
    "    correct += (tag_scores.argmax(-1) == targets).sum()\n",
    "    total += len(targets)\n",
    "    \n",
    "print(float(correct) / float(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
