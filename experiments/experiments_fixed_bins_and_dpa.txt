##############################################################

$ python eval.py --model_dir saved_models/aaa_bins_12
Loading model from saved_models/aaa_bins_12/best_model.pt
Number of heads:  3
d_v and d_k:  120.0
Fine-tune all embeddings.
Using weights [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Vocab size 55950 loaded from file
Loading data from dataset/tacred/test.json with batch size 50...
100%|██████████| 15509/15509 [00:01<00:00, 9149.86it/s]
311 batches created for dataset/tacred/test.json

Running with the following configs:
        data_dir : dataset/tacred
        vocab_dir : dataset/vocab
        emb_dim : 300
        ner_dim : 30
        pos_dim : 30
        hidden_dim : 360
        hidden_self : 130
        query_size_attn : 360
        num_layers : 2
        num_layers_encoder : 1
        dropout : 0.4
        scaled_dropout : 0.1
        temper_value : 0.5
        word_dropout : 0.06
        lstm_dropout : 0.5
        topn : 10000000000.0
        lower : False
        weight_no_rel : 1.0
        weight_rest : 1.0
        self_att : True
        self_att_and_rnn : False
        use_lemmas : False
        preload_lemmas : False
        obj_sub_pos : True
        use_batch_norm : True
        diagonal_positional_attention : True
        relative_positions : True
        new_residual : True
        n_head : 3
        attn : True
        attn_dim : 200
        pe_dim : 30
        lr : 0.1
        lr_decay : 0.9
        decay_epoch : 15
        optim : sgd
        num_epoch : 200
        batch_size : 50
        max_grad_norm : 5.0
        log_step : 400
        log : logs.txt
        save_epoch : 10
        save_dir : ./saved_models
        id : aaa_bins_12
        info :
        seed : 1234
        cuda : True
        cpu : False
        num_class : 42
        vocab_size : 55950
        model_save_dir : ./saved_models/aaa_bins_12


Per-relation statistics:
org:alternate_names                  P:  76.08%  R:  74.65%  F1:  75.36%  #: 213
org:city_of_headquarters             P:  69.41%  R:  71.95%  F1:  70.66%  #: 82
org:country_of_headquarters          P:  62.82%  R:  45.37%  F1:  52.69%  #: 108
org:dissolved                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
org:founded                          P:  82.50%  R:  89.19%  F1:  85.71%  #: 37
org:founded_by                       P:  69.70%  R:  33.82%  F1:  45.54%  #: 68
org:member_of                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 18
org:members                          P:   0.00%  R:   0.00%  F1:   0.00%  #: 31
org:number_of_employees/members      P:  60.87%  R:  73.68%  F1:  66.67%  #: 19
org:parents                          P:  38.10%  R:  12.90%  F1:  19.28%  #: 62
org:political/religious_affiliation  P:  23.33%  R:  70.00%  F1:  35.00%  #: 10
org:shareholders                     P: 100.00%  R:  23.08%  F1:  37.50%  #: 13
org:stateorprovince_of_headquarters  P:  72.55%  R:  72.55%  F1:  72.55%  #: 51
org:subsidiaries                     P:  40.62%  R:  29.55%  F1:  34.21%  #: 44
org:top_members/employees            P:  61.89%  R:  87.28%  F1:  72.42%  #: 346
org:website                          P:  55.56%  R:  96.15%  F1:  70.42%  #: 26
per:age                              P:  73.31%  R:  92.00%  F1:  81.60%  #: 200
per:alternate_names                  P:   0.00%  R:   0.00%  F1:   0.00%  #: 11
per:cause_of_death                   P:  61.90%  R:  50.00%  F1:  55.32%  #: 52
per:charges                          P:  64.06%  R:  79.61%  F1:  71.00%  #: 103
per:children                         P:  42.50%  R:  45.95%  F1:  44.16%  #: 37
per:cities_of_residence              P:  56.63%  R:  58.73%  F1:  57.66%  #: 189
per:city_of_birth                    P:  50.00%  R:  20.00%  F1:  28.57%  #: 5
per:city_of_death                    P: 100.00%  R:  28.57%  F1:  44.44%  #: 28
per:countries_of_residence           P:  46.67%  R:  52.03%  F1:  49.20%  #: 148
per:country_of_birth                 P:   0.00%  R:   0.00%  F1:   0.00%  #: 5
per:country_of_death                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 9
per:date_of_birth                    P:  77.78%  R:  77.78%  F1:  77.78%  #: 9
per:date_of_death                    P:  69.23%  R:  33.33%  F1:  45.00%  #: 54
per:employee_of                      P:  71.30%  R:  60.23%  F1:  65.30%  #: 264
per:origin                           P:  66.67%  R:  59.09%  F1:  62.65%  #: 132
per:other_family                     P:  70.27%  R:  43.33%  F1:  53.61%  #: 60
per:parents                          P:  58.62%  R:  57.95%  F1:  58.29%  #: 88
per:religion                         P:  45.76%  R:  57.45%  F1:  50.94%  #: 47
per:schools_attended                 P:  68.00%  R:  56.67%  F1:  61.82%  #: 30
per:siblings                         P:  66.07%  R:  67.27%  F1:  66.67%  #: 55
per:spouse                           P:  51.72%  R:  68.18%  F1:  58.82%  #: 66
per:stateorprovince_of_birth         P:  57.14%  R:  50.00%  F1:  53.33%  #: 8
per:stateorprovince_of_death         P:  66.67%  R:  14.29%  F1:  23.53%  #: 14
per:stateorprovinces_of_residence    P:  62.20%  R:  62.96%  F1:  62.58%  #: 81
per:title                            P:  74.91%  R:  87.20%  F1:  80.59%  #: 500

Final Score:
Calculating Precision: correct_by_relation= 2196.0 / guessed_by_relation= 3375.0
Calculating Recall: correct_by_relation= 2196.0 / gold_by_relation= 3325.0
only_non_relation: 3325.0
Precision (micro): 65.067%
   Recall (micro): 66.045%
       F1 (micro): 65.552%
Prediction scores saved to saved_models/out/test_6.pkl.
Evaluation ended.
(cuda2)


#########################################################################################

# same but eval epoch 60

Per-relation statistics:
org:alternate_names                  P:  76.39%  R:  77.46%  F1:  76.92%  #: 213
org:city_of_headquarters             P:  67.86%  R:  69.51%  F1:  68.67%  #: 82
org:country_of_headquarters          P:  63.16%  R:  44.44%  F1:  52.17%  #: 108
org:dissolved                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
org:founded                          P:  84.62%  R:  89.19%  F1:  86.84%  #: 37
org:founded_by                       P:  72.09%  R:  45.59%  F1:  55.86%  #: 68
org:member_of                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 18
org:members                          P:   0.00%  R:   0.00%  F1:   0.00%  #: 31
org:number_of_employees/members      P:  65.00%  R:  68.42%  F1:  66.67%  #: 19
org:parents                          P:  38.46%  R:  16.13%  F1:  22.73%  #: 62
org:political/religious_affiliation  P:  20.00%  R:  80.00%  F1:  32.00%  #: 10
org:shareholders                     P: 100.00%  R:  23.08%  F1:  37.50%  #: 13
org:stateorprovince_of_headquarters  P:  70.59%  R:  70.59%  F1:  70.59%  #: 51
org:subsidiaries                     P:  50.00%  R:  29.55%  F1:  37.14%  #: 44
org:top_members/employees            P:  64.77%  R:  85.55%  F1:  73.72%  #: 346
org:website                          P:  53.33%  R:  92.31%  F1:  67.61%  #: 26
per:age                              P:  73.98%  R:  91.00%  F1:  81.61%  #: 200
per:alternate_names                  P:   0.00%  R:   0.00%  F1:   0.00%  #: 11
per:cause_of_death                   P:  64.10%  R:  48.08%  F1:  54.95%  #: 52
per:charges                          P:  61.11%  R:  96.12%  F1:  74.72%  #: 103
per:children                         P:  36.36%  R:  43.24%  F1:  39.51%  #: 37
per:cities_of_residence              P:  49.79%  R:  62.43%  F1:  55.40%  #: 189
per:city_of_birth                    P:  50.00%  R:  20.00%  F1:  28.57%  #: 5
per:city_of_death                    P: 100.00%  R:  25.00%  F1:  40.00%  #: 28
per:countries_of_residence           P:  44.16%  R:  58.78%  F1:  50.43%  #: 148
per:country_of_birth                 P:   0.00%  R:   0.00%  F1:   0.00%  #: 5
per:country_of_death                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 9
per:date_of_birth                    P:  77.78%  R:  77.78%  F1:  77.78%  #: 9
per:date_of_death                    P:  67.86%  R:  35.19%  F1:  46.34%  #: 54
per:employee_of                      P:  64.39%  R:  67.80%  F1:  66.05%  #: 264
per:origin                           P:  61.03%  R:  62.88%  F1:  61.94%  #: 132
per:other_family                     P:  66.67%  R:  43.33%  F1:  52.53%  #: 60
per:parents                          P:  57.65%  R:  55.68%  F1:  56.65%  #: 88
per:religion                         P:  45.71%  R:  68.09%  F1:  54.70%  #: 47
per:schools_attended                 P:  68.00%  R:  56.67%  F1:  61.82%  #: 30
per:siblings                         P:  66.07%  R:  67.27%  F1:  66.67%  #: 55
per:spouse                           P:  50.55%  R:  69.70%  F1:  58.60%  #: 66
per:stateorprovince_of_birth         P:  50.00%  R:  50.00%  F1:  50.00%  #: 8
per:stateorprovince_of_death         P:  80.00%  R:  28.57%  F1:  42.11%  #: 14
per:stateorprovinces_of_residence    P:  62.65%  R:  64.20%  F1:  63.41%  #: 81
per:title                            P:  73.47%  R:  88.60%  F1:  80.33%  #: 500

Final Score:
Calculating Precision: correct_by_relation= 2270.0 / guessed_by_relation= 3581.0
Calculating Recall: correct_by_relation= 2270.0 / gold_by_relation= 3325.0
only_non_relation: 3325.0
Precision (micro): 63.390%
   Recall (micro): 68.271%
       F1 (micro): 65.740%


##########################################################################################

# best so far, with random seed 3333

$ python eval.py --model_dir saved_models/aaa_bins_13 --model checkpoint_epoch_6                                 0.pt
Loading model from saved_models/aaa_bins_13/checkpoint_epoch_60.pt
Number of heads:  3
d_v and d_k:  120.0
Vocab size 55950 loaded from file
Fine-tune all embeddings.
Using weights [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,                                  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,                                  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Vocab size 55950 loaded from file
Loading data from dataset/tacred/test.json with batch size 50...
100%|██████████| 15509/15509 [00:01<00:00, 9392.91it/s]
311 batches created for dataset/tacred/test.json

Running with the following configs:
        data_dir : dataset/tacred
        vocab_dir : dataset/vocab
        emb_dim : 300
        ner_dim : 30
        pos_dim : 30
        hidden_dim : 360
        hidden_self : 130
        query_size_attn : 360
        num_layers : 2
        num_layers_encoder : 1
        dropout : 0.4
        scaled_dropout : 0.1
        temper_value : 0.5
        word_dropout : 0.06
        lstm_dropout : 0.5
        topn : 10000000000.0
        lower : False
        weight_no_rel : 1.0
        weight_rest : 1.0
        self_att : True
        self_att_and_rnn : False
        use_lemmas : False
        preload_lemmas : False
        obj_sub_pos : True
        use_batch_norm : True
        diagonal_positional_attention : True
        relative_positions : True
        new_residual : True
        n_head : 3
        attn : True
        attn_dim : 200
        pe_dim : 30
        lr : 0.1
        lr_decay : 0.9
        decay_epoch : 15
        optim : sgd
        num_epoch : 200
        batch_size : 50
        max_grad_norm : 5.0
        log_step : 400
        log : logs.txt
        save_epoch : 10
        save_dir : ./saved_models
        id : aaa_bins_13
        info :
        seed : 3333
        cuda : True
        cpu : False
        num_class : 42
        vocab_size : 55950
        model_save_dir : ./saved_models/aaa_bins_13


Per-relation statistics:
org:alternate_names                  P:  75.66%  R:  80.28%  F1:  77.90%  #: 213
org:city_of_headquarters             P:  69.57%  R:  78.05%  F1:  73.56%  #: 82
org:country_of_headquarters          P:  72.00%  R:  33.33%  F1:  45.57%  #: 108
org:dissolved                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
org:founded                          P:  78.57%  R:  89.19%  F1:  83.54%  #: 37
org:founded_by                       P:  72.73%  R:  35.29%  F1:  47.52%  #: 68
org:member_of                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 18
org:members                          P:  20.00%  R:   3.23%  F1:   5.56%  #: 31
org:number_of_employees/members      P:  60.00%  R:  78.95%  F1:  68.18%  #: 19
org:parents                          P:  29.03%  R:  14.52%  F1:  19.35%  #: 62
org:political/religious_affiliation  P:  25.00%  R:  70.00%  F1:  36.84%  #: 10
org:shareholders                     P:  80.00%  R:  30.77%  F1:  44.44%  #: 13
org:stateorprovince_of_headquarters  P:  65.62%  R:  82.35%  F1:  73.04%  #: 51
org:subsidiaries                     P:  41.18%  R:  31.82%  F1:  35.90%  #: 44
org:top_members/employees            P:  59.88%  R:  88.44%  F1:  71.41%  #: 346
org:website                          P:  54.55%  R:  92.31%  F1:  68.57%  #: 26
per:age                              P:  80.93%  R:  95.50%  F1:  87.61%  #: 200
per:alternate_names                  P:   0.00%  R:   0.00%  F1:   0.00%  #: 11
per:cause_of_death                   P:  65.85%  R:  51.92%  F1:  58.06%  #: 52
per:charges                          P:  59.06%  R:  98.06%  F1:  73.72%  #: 103
per:children                         P:  34.00%  R:  45.95%  F1:  39.08%  #: 37
per:cities_of_residence              P:  55.90%  R:  57.67%  F1:  56.77%  #: 189
per:city_of_birth                    P:  50.00%  R:  20.00%  F1:  28.57%  #: 5
per:city_of_death                    P: 100.00%  R:  35.71%  F1:  52.63%  #: 28
per:countries_of_residence           P:  48.20%  R:  45.27%  F1:  46.69%  #: 148
per:country_of_birth                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 5
per:country_of_death                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 9
per:date_of_birth                    P:  53.85%  R:  77.78%  F1:  63.64%  #: 9
per:date_of_death                    P:  52.94%  R:  50.00%  F1:  51.43%  #: 54
per:employee_of                      P:  61.92%  R:  65.91%  F1:  63.85%  #: 264
per:origin                           P:  57.79%  R:  67.42%  F1:  62.24%  #: 132
per:other_family                     P:  62.50%  R:  50.00%  F1:  55.56%  #: 60
per:parents                          P:  58.62%  R:  57.95%  F1:  58.29%  #: 88
per:religion                         P:  43.62%  R:  87.23%  F1:  58.16%  #: 47
per:schools_attended                 P:  59.26%  R:  53.33%  F1:  56.14%  #: 30
per:siblings                         P:  64.41%  R:  69.09%  F1:  66.67%  #: 55
per:spouse                           P:  56.79%  R:  69.70%  F1:  62.59%  #: 66
per:stateorprovince_of_birth         P:  40.00%  R:  50.00%  F1:  44.44%  #: 8
per:stateorprovince_of_death         P:  50.00%  R:  35.71%  F1:  41.67%  #: 14
per:stateorprovinces_of_residence    P:  67.95%  R:  65.43%  F1:  66.67%  #: 81
per:title                            P:  74.32%  R:  87.40%  F1:  80.33%  #: 500

Final Score:
Calculating Precision: correct_by_relation= 2291.0 / guessed_by_relation= 3619.0
Calculating Recall: correct_by_relation= 2291.0 / gold_by_relation= 3325.0
only_non_relation: 3325.0
Precision (micro): 63.305%
   Recall (micro): 68.902%
       F1 (micro): 65.985%
Prediction scores saved to saved_models/out/test_6.pkl.
Evaluation ended.
(cuda2)



#######################################################################################

# best so far!!!

$ python eval.py --model_dir saved_models/aaa_bins_15 --model checkpoint_epoch_60.pt
Loading model from saved_models/aaa_bins_15/checkpoint_epoch_60.pt
Number of heads:  3
d_v and d_k:  120.0
Vocab size 55950 loaded from file
Fine-tune all embeddings.
Using weights [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Vocab size 55950 loaded from file
Loading data from dataset/tacred/test.json with batch size 50...
100%|██████████| 15509/15509 [00:01<00:00, 10098.37it/s]
311 batches created for dataset/tacred/test.json

Running with the following configs:
        data_dir : dataset/tacred
        vocab_dir : dataset/vocab
        emb_dim : 300
        ner_dim : 30
        pos_dim : 30
        hidden_dim : 360
        hidden_self : 130
        query_size_attn : 360
        num_layers : 2
        num_layers_encoder : 1
        dropout : 0.4
        scaled_dropout : 0.1
        temper_value : 0.5
        word_dropout : 0.06
        lstm_dropout : 0.5
        topn : 10000000000.0
        lower : False
        weight_no_rel : 1.0
        weight_rest : 1.0
        self_att : True
        self_att_and_rnn : False
        use_lemmas : False
        preload_lemmas : False
        obj_sub_pos : True
        use_batch_norm : True
        diagonal_positional_attention : True
        relative_positions : True
        new_residual : True
        n_head : 3
        attn : True
        attn_dim : 200
        pe_dim : 30
        lr : 0.1
        lr_decay : 0.9
        decay_epoch : 15
        optim : sgd
        num_epoch : 100
        batch_size : 50
        max_grad_norm : 5.0
        log_step : 400
        log : logs.txt
        save_epoch : 10
        save_dir : ./saved_models
        id : aaa_bins_15
        info :
        seed : 1234
        cuda : True
        cpu : False
        num_class : 42
        vocab_size : 55950
        model_save_dir : ./saved_models/aaa_bins_15


Per-relation statistics:
org:alternate_names                  P:  76.24%  R:  72.30%  F1:  74.22%  #: 213
org:city_of_headquarters             P:  70.24%  R:  71.95%  F1:  71.08%  #: 82
org:country_of_headquarters          P:  66.18%  R:  41.67%  F1:  51.14%  #: 108
org:dissolved                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
org:founded                          P:  88.89%  R:  86.49%  F1:  87.67%  #: 37
org:founded_by                       P:  76.32%  R:  42.65%  F1:  54.72%  #: 68
org:member_of                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 18
org:members                          P:  33.33%  R:   3.23%  F1:   5.88%  #: 31
org:number_of_employees/members      P:  68.42%  R:  68.42%  F1:  68.42%  #: 19
org:parents                          P:  54.17%  R:  20.97%  F1:  30.23%  #: 62
org:political/religious_affiliation  P:  22.86%  R:  80.00%  F1:  35.56%  #: 10
org:shareholders                     P:  80.00%  R:  30.77%  F1:  44.44%  #: 13
org:stateorprovince_of_headquarters  P:  68.42%  R:  76.47%  F1:  72.22%  #: 51
org:subsidiaries                     P:  48.57%  R:  38.64%  F1:  43.04%  #: 44
org:top_members/employees            P:  66.22%  R:  84.97%  F1:  74.43%  #: 346
org:website                          P:  55.81%  R:  92.31%  F1:  69.57%  #: 26
per:age                              P:  78.97%  R:  92.00%  F1:  84.99%  #: 200
per:alternate_names                  P:   0.00%  R:   0.00%  F1:   0.00%  #: 11
per:cause_of_death                   P:  65.79%  R:  48.08%  F1:  55.56%  #: 52
per:charges                          P:  65.49%  R:  90.29%  F1:  75.92%  #: 103
per:children                         P:  39.02%  R:  43.24%  F1:  41.03%  #: 37
per:cities_of_residence              P:  47.89%  R:  66.14%  F1:  55.56%  #: 189
per:city_of_birth                    P:  50.00%  R:  20.00%  F1:  28.57%  #: 5
per:city_of_death                    P:  90.00%  R:  32.14%  F1:  47.37%  #: 28
per:countries_of_residence           P:  39.84%  R:  66.22%  F1:  49.75%  #: 148
per:country_of_birth                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 5
per:country_of_death                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 9
per:date_of_birth                    P:  77.78%  R:  77.78%  F1:  77.78%  #: 9
per:date_of_death                    P:  61.11%  R:  40.74%  F1:  48.89%  #: 54
per:employee_of                      P:  62.59%  R:  69.70%  F1:  65.95%  #: 264
per:origin                           P:  62.60%  R:  62.12%  F1:  62.36%  #: 132
per:other_family                     P:  65.85%  R:  45.00%  F1:  53.47%  #: 60
per:parents                          P:  63.41%  R:  59.09%  F1:  61.18%  #: 88
per:religion                         P:  44.05%  R:  78.72%  F1:  56.49%  #: 47
per:schools_attended                 P:  72.73%  R:  53.33%  F1:  61.54%  #: 30
per:siblings                         P:  64.41%  R:  69.09%  F1:  66.67%  #: 55
per:spouse                           P:  55.00%  R:  66.67%  F1:  60.27%  #: 66
per:stateorprovince_of_birth         P:  44.44%  R:  50.00%  F1:  47.06%  #: 8
per:stateorprovince_of_death         P:  62.50%  R:  35.71%  F1:  45.45%  #: 14
per:stateorprovinces_of_residence    P:  59.14%  R:  67.90%  F1:  63.22%  #: 81
per:title                            P:  73.49%  R:  87.60%  F1:  79.93%  #: 500

Final Score:
Calculating Precision: correct_by_relation= 2294.0 / guessed_by_relation= 3612.0
Calculating Recall: correct_by_relation= 2294.0 / gold_by_relation= 3325.0
only_non_relation: 3325.0
Precision (micro): 63.511%
   Recall (micro): 68.992%
       F1 (micro): 66.138%
Prediction scores saved to saved_models/out/test_6.pkl.
Evaluation ended.

# checkpoint epoch 60

########################################################################

$ python eval.py --model_dir saved_models/aaa_bins_15 --model checkpoint_epoch_100.pt
Loading model from saved_models/aaa_bins_15/checkpoint_epoch_100.pt
Number of heads:  3
d_v and d_k:  120.0
Vocab size 55950 loaded from file
Fine-tune all embeddings.
Using weights [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Vocab size 55950 loaded from file
Loading data from dataset/tacred/test.json with batch size 50...
100%|██████████| 15509/15509 [00:01<00:00, 10116.76it/s]
311 batches created for dataset/tacred/test.json

Running with the following configs:
        data_dir : dataset/tacred
        vocab_dir : dataset/vocab
        emb_dim : 300
        ner_dim : 30
        pos_dim : 30
        hidden_dim : 360
        hidden_self : 130
        query_size_attn : 360
        num_layers : 2
        num_layers_encoder : 1
        dropout : 0.4
        scaled_dropout : 0.1
        temper_value : 0.5
        word_dropout : 0.06
        lstm_dropout : 0.5
        topn : 10000000000.0
        lower : False
        weight_no_rel : 1.0
        weight_rest : 1.0
        self_att : True
        self_att_and_rnn : False
        use_lemmas : False
        preload_lemmas : False
        obj_sub_pos : True
        use_batch_norm : True
        diagonal_positional_attention : True
        relative_positions : True
        new_residual : True
        n_head : 3
        attn : True
        attn_dim : 200
        pe_dim : 30
        lr : 0.1
        lr_decay : 0.9
        decay_epoch : 15
        optim : sgd
        num_epoch : 100
        batch_size : 50
        max_grad_norm : 5.0
        log_step : 400
        log : logs.txt
        save_epoch : 10
        save_dir : ./saved_models
        id : aaa_bins_15
        info :
        seed : 1234
        cuda : True
        cpu : False
        num_class : 42
        vocab_size : 55950
        model_save_dir : ./saved_models/aaa_bins_15


Per-relation statistics:
org:alternate_names                  P:  76.04%  R:  77.46%  F1:  76.74%  #: 213
org:city_of_headquarters             P:  69.23%  R:  76.83%  F1:  72.83%  #: 82
org:country_of_headquarters          P:  63.89%  R:  42.59%  F1:  51.11%  #: 108
org:dissolved                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
org:founded                          P:  82.05%  R:  86.49%  F1:  84.21%  #: 37
org:founded_by                       P:  75.00%  R:  44.12%  F1:  55.56%  #: 68
org:member_of                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 18
org:members                          P:  33.33%  R:   6.45%  F1:  10.81%  #: 31
org:number_of_employees/members      P:  66.67%  R:  73.68%  F1:  70.00%  #: 19
org:parents                          P:  42.86%  R:  24.19%  F1:  30.93%  #: 62
org:political/religious_affiliation  P:  21.88%  R:  70.00%  F1:  33.33%  #: 10
org:shareholders                     P:  66.67%  R:  30.77%  F1:  42.11%  #: 13
org:stateorprovince_of_headquarters  P:  64.06%  R:  80.39%  F1:  71.30%  #: 51
org:subsidiaries                     P:  45.95%  R:  38.64%  F1:  41.98%  #: 44
org:top_members/employees            P:  66.13%  R:  83.53%  F1:  73.82%  #: 346
org:website                          P:  61.54%  R:  92.31%  F1:  73.85%  #: 26
per:age                              P:  79.15%  R:  93.00%  F1:  85.52%  #: 200
per:alternate_names                  P:   0.00%  R:   0.00%  F1:   0.00%  #: 11
per:cause_of_death                   P:  69.44%  R:  48.08%  F1:  56.82%  #: 52
per:charges                          P:  62.75%  R:  93.20%  F1:  75.00%  #: 103
per:children                         P:  36.36%  R:  43.24%  F1:  39.51%  #: 37
per:cities_of_residence              P:  49.15%  R:  61.38%  F1:  54.59%  #: 189
per:city_of_birth                    P:  50.00%  R:  20.00%  F1:  28.57%  #: 5
per:city_of_death                    P:  91.67%  R:  39.29%  F1:  55.00%  #: 28
per:countries_of_residence           P:  48.82%  R:  56.08%  F1:  52.20%  #: 148
per:country_of_birth                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 5
per:country_of_death                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 9
per:date_of_birth                    P:  77.78%  R:  77.78%  F1:  77.78%  #: 9
per:date_of_death                    P:  57.50%  R:  42.59%  F1:  48.94%  #: 54
per:employee_of                      P:  60.52%  R:  70.83%  F1:  65.27%  #: 264
per:origin                           P:  60.14%  R:  65.15%  F1:  62.55%  #: 132
per:other_family                     P:  62.50%  R:  50.00%  F1:  55.56%  #: 60
per:parents                          P:  57.61%  R:  60.23%  F1:  58.89%  #: 88
per:religion                         P:  45.95%  R:  72.34%  F1:  56.20%  #: 47
per:schools_attended                 P:  70.83%  R:  56.67%  F1:  62.96%  #: 30
per:siblings                         P:  58.21%  R:  70.91%  F1:  63.93%  #: 55
per:spouse                           P:  57.14%  R:  66.67%  F1:  61.54%  #: 66
per:stateorprovince_of_birth         P:  36.36%  R:  50.00%  F1:  42.11%  #: 8
per:stateorprovince_of_death         P:  60.00%  R:  42.86%  F1:  50.00%  #: 14
per:stateorprovinces_of_residence    P:  61.45%  R:  62.96%  F1:  62.20%  #: 81
per:title                            P:  74.10%  R:  86.40%  F1:  79.78%  #: 500

Final Score:
Calculating Precision: correct_by_relation= 2296.0 / guessed_by_relation= 3599.0
Calculating Recall: correct_by_relation= 2296.0 / gold_by_relation= 3325.0
only_non_relation: 3325.0
Precision (micro): 63.795%
   Recall (micro): 69.053%
       F1 (micro): 66.320%
Prediction scores saved to saved_models/out/test_6.pkl.
Evaluation ended.

# checkpoint epoch 100
--seed 1234

#########################################################################################


# best results!!!!

$ python eval.py --model_dir saved_models/aaa_bins_18 --model checkpoint_epoch_60.pt
Loading model from saved_models/aaa_bins_18/checkpoint_epoch_60.pt
Number of heads:  3
d_v and d_k:  120.0
Vocab size 55950 loaded from file
Fine-tune all embeddings.
Using weights [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Vocab size 55950 loaded from file
Loading data from dataset/tacred/test.json with batch size 50...
100%|██████████| 15509/15509 [00:01<00:00, 10096.71it/s]
311 batches created for dataset/tacred/test.json

Running with the following configs:
        data_dir : dataset/tacred
        vocab_dir : dataset/vocab
        emb_dim : 300
        ner_dim : 30
        pos_dim : 30
        hidden_dim : 360
        hidden_self : 130
        query_size_attn : 360
        num_layers : 2
        num_layers_encoder : 1
        dropout : 0.4
        scaled_dropout : 0.1
        temper_value : 0.5
        word_dropout : 0.06
        lstm_dropout : 0.5
        topn : 10000000000.0
        lower : False
        weight_no_rel : 1.0
        weight_rest : 1.0
        self_att : True
        self_att_and_rnn : False
        use_lemmas : False
        preload_lemmas : False
        obj_sub_pos : True
        use_batch_norm : True
        diagonal_positional_attention : True
        relative_positions : True
        new_residual : True
        n_head : 3
        attn : True
        attn_dim : 200
        pe_dim : 30
        lr : 0.1
        lr_decay : 0.9
        decay_epoch : 15
        optim : sgd
        num_epoch : 100
        batch_size : 50
        max_grad_norm : 1.0
        log_step : 400
        log : logs.txt
        save_epoch : 10
        save_dir : ./saved_models
        id : aaa_bins_18
        info :
        seed : 1234
        cuda : True
        cpu : False
        num_class : 42
        vocab_size : 55950
        model_save_dir : ./saved_models/aaa_bins_18


Per-relation statistics:
org:alternate_names                  P:  75.44%  R:  80.75%  F1:  78.00%  #: 213
org:city_of_headquarters             P:  70.45%  R:  75.61%  F1:  72.94%  #: 82
org:country_of_headquarters          P:  57.14%  R:  40.74%  F1:  47.57%  #: 108
org:dissolved                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
org:founded                          P:  82.05%  R:  86.49%  F1:  84.21%  #: 37
org:founded_by                       P:  69.44%  R:  36.76%  F1:  48.08%  #: 68
org:member_of                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 18
org:members                          P:   0.00%  R:   0.00%  F1:   0.00%  #: 31
org:number_of_employees/members      P:  65.22%  R:  78.95%  F1:  71.43%  #: 19
org:parents                          P:  38.46%  R:  16.13%  F1:  22.73%  #: 62
org:political/religious_affiliation  P:  24.24%  R:  80.00%  F1:  37.21%  #: 10
org:shareholders                     P:  80.00%  R:  30.77%  F1:  44.44%  #: 13
org:stateorprovince_of_headquarters  P:  65.08%  R:  80.39%  F1:  71.93%  #: 51
org:subsidiaries                     P:  53.33%  R:  36.36%  F1:  43.24%  #: 44
org:top_members/employees            P:  64.41%  R:  85.26%  F1:  73.38%  #: 346
org:website                          P:  54.55%  R:  92.31%  F1:  68.57%  #: 26
per:age                              P:  79.82%  R:  91.00%  F1:  85.05%  #: 200
per:alternate_names                  P:   0.00%  R:   0.00%  F1:   0.00%  #: 11
per:cause_of_death                   P:  63.64%  R:  40.38%  F1:  49.41%  #: 52
per:charges                          P:  68.94%  R:  88.35%  F1:  77.45%  #: 103
per:children                         P:  40.48%  R:  45.95%  F1:  43.04%  #: 37
per:cities_of_residence              P:  50.62%  R:  64.55%  F1:  56.74%  #: 189
per:city_of_birth                    P:  50.00%  R:  20.00%  F1:  28.57%  #: 5
per:city_of_death                    P: 100.00%  R:  21.43%  F1:  35.29%  #: 28
per:countries_of_residence           P:  43.28%  R:  58.78%  F1:  49.86%  #: 148
per:country_of_birth                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 5
per:country_of_death                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 9
per:date_of_birth                    P:  77.78%  R:  77.78%  F1:  77.78%  #: 9
per:date_of_death                    P:  66.67%  R:  37.04%  F1:  47.62%  #: 54
per:employee_of                      P:  64.36%  R:  70.45%  F1:  67.27%  #: 264
per:origin                           P:  68.70%  R:  59.85%  F1:  63.97%  #: 132
per:other_family                     P:  66.67%  R:  43.33%  F1:  52.53%  #: 60
per:parents                          P:  59.78%  R:  62.50%  F1:  61.11%  #: 88
per:religion                         P:  44.00%  R:  70.21%  F1:  54.10%  #: 47
per:schools_attended                 P:  64.29%  R:  60.00%  F1:  62.07%  #: 30
per:siblings                         P:  63.33%  R:  69.09%  F1:  66.09%  #: 55
per:spouse                           P:  56.25%  R:  68.18%  F1:  61.64%  #: 66
per:stateorprovince_of_birth         P:  40.00%  R:  50.00%  F1:  44.44%  #: 8
per:stateorprovince_of_death         P:  83.33%  R:  35.71%  F1:  50.00%  #: 14
per:stateorprovinces_of_residence    P:  62.96%  R:  62.96%  F1:  62.96%  #: 81
per:title                            P:  76.70%  R:  85.60%  F1:  80.91%  #: 500

Final Score:
Calculating Precision: correct_by_relation= 2270.0 / guessed_by_relation= 3512.0
Calculating Recall: correct_by_relation= 2270.0 / gold_by_relation= 3325.0
only_non_relation: 3325.0
Precision (micro): 64.636%
   Recall (micro): 68.271%
       F1 (micro): 66.403%
Prediction scores saved to saved_models/out/test_6.pkl.
Evaluation ended.

# checkpoint model 60
# seed 1234
# max_norm 1.0

# same but epoch 100
Precision (micro): 64.302%
   Recall (micro): 68.692%
       F1 (micro): 66.424%

# checkpoint best model
Precision (micro): 64.835%
   Recall (micro): 68.150%
       F1 (micro): 66.452%


####################################################################################


# set --attn_dim to 1000:

$ python eval.py --model_dir saved_models/aaa_bins_35 --model checkpoint_epoch_70.pt
Loading model from saved_models/aaa_bins_35/checkpoint_epoch_70.pt
Number of heads:  3
d_v and d_k:  120.0
Vocab size 55950 loaded from file
Fine-tune all embeddings.
Using weights [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Vocab size 55950 loaded from file
Loading data from dataset/tacred/test.json with batch size 50...
100%|██████████| 15509/15509 [00:01<00:00, 8236.32it/s]
311 batches created for dataset/tacred/test.json

Running with the following configs:
        data_dir : dataset/tacred
        vocab_dir : dataset/vocab
        emb_dim : 300
        ner_dim : 30
        pos_dim : 30
        hidden_dim : 360
        hidden_self : 130
        query_size_attn : 360
        num_layers : 2
        num_layers_encoder : 1
        dropout : 0.4
        scaled_dropout : 0.1
        temper_value : 0.5
        word_dropout : 0.06
        lstm_dropout : 0.5
        topn : 10000000000.0
        lower : False
        weight_no_rel : 1.0
        weight_rest : 1.0
        self_att : True
        self_att_and_rnn : False
        use_lemmas : False
        preload_lemmas : False
        obj_sub_pos : True
        use_batch_norm : True
        diagonal_positional_attention : True
        relative_positions : True
        new_residual : True
        n_head : 3
        attn : True
        attn_dim : 1000
        pe_dim : 30
        lr : 0.1
        lr_decay : 0.9
        decay_epoch : 15
        optim : sgd
        num_epoch : 100
        batch_size : 50
        max_grad_norm : 1.0
        log_step : 400
        log : logs.txt
        save_epoch : 10
        save_dir : ./saved_models
        id : aaa_bins_35
        info :
        seed : 1234
        cuda : True
        cpu : False
        num_class : 42
        vocab_size : 55950
        model_save_dir : ./saved_models/aaa_bins_35


Per-relation statistics:
org:alternate_names                  P:  76.21%  R:  81.22%  F1:  78.64%  #: 213
org:city_of_headquarters             P:  70.79%  R:  76.83%  F1:  73.68%  #: 82
org:country_of_headquarters          P:  56.32%  R:  45.37%  F1:  50.26%  #: 108
org:dissolved                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
org:founded                          P:  86.84%  R:  89.19%  F1:  88.00%  #: 37
org:founded_by                       P:  68.09%  R:  47.06%  F1:  55.65%  #: 68
org:member_of                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 18
org:members                          P:  20.00%  R:   3.23%  F1:   5.56%  #: 31
org:number_of_employees/members      P:  60.87%  R:  73.68%  F1:  66.67%  #: 19
org:parents                          P:  42.86%  R:  14.52%  F1:  21.69%  #: 62
org:political/religious_affiliation  P:  23.33%  R:  70.00%  F1:  35.00%  #: 10
org:shareholders                     P:  50.00%  R:  23.08%  F1:  31.58%  #: 13
org:stateorprovince_of_headquarters  P:  66.10%  R:  76.47%  F1:  70.91%  #: 51
org:subsidiaries                     P:  51.61%  R:  36.36%  F1:  42.67%  #: 44
org:top_members/employees            P:  66.44%  R:  84.10%  F1:  74.23%  #: 346
org:website                          P:  53.33%  R:  92.31%  F1:  67.61%  #: 26
per:age                              P:  77.33%  R:  95.50%  F1:  85.46%  #: 200
per:alternate_names                  P:   0.00%  R:   0.00%  F1:   0.00%  #: 11
per:cause_of_death                   P:  65.79%  R:  48.08%  F1:  55.56%  #: 52
per:charges                          P:  60.00%  R:  93.20%  F1:  73.00%  #: 103
per:children                         P:  36.36%  R:  43.24%  F1:  39.51%  #: 37
per:cities_of_residence              P:  50.87%  R:  61.90%  F1:  55.85%  #: 189
per:city_of_birth                    P:  50.00%  R:  20.00%  F1:  28.57%  #: 5
per:city_of_death                    P: 100.00%  R:  25.00%  F1:  40.00%  #: 28
per:countries_of_residence           P:  43.82%  R:  52.70%  F1:  47.85%  #: 148
per:country_of_birth                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 5
per:country_of_death                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 9
per:date_of_birth                    P:  85.71%  R:  66.67%  F1:  75.00%  #: 9
per:date_of_death                    P:  69.23%  R:  33.33%  F1:  45.00%  #: 54
per:employee_of                      P:  67.03%  R:  69.32%  F1:  68.16%  #: 264
per:origin                           P:  67.83%  R:  59.09%  F1:  63.16%  #: 132
per:other_family                     P:  66.67%  R:  43.33%  F1:  52.53%  #: 60
per:parents                          P:  58.33%  R:  55.68%  F1:  56.98%  #: 88
per:religion                         P:  42.86%  R:  63.83%  F1:  51.28%  #: 47
per:schools_attended                 P:  64.29%  R:  60.00%  F1:  62.07%  #: 30
per:siblings                         P:  61.29%  R:  69.09%  F1:  64.96%  #: 55
per:spouse                           P:  57.53%  R:  63.64%  F1:  60.43%  #: 66
per:stateorprovince_of_birth         P:  57.14%  R:  50.00%  F1:  53.33%  #: 8
per:stateorprovince_of_death         P:  80.00%  R:  28.57%  F1:  42.11%  #: 14
per:stateorprovinces_of_residence    P:  59.77%  R:  64.20%  F1:  61.90%  #: 81
per:title                            P:  73.23%  R:  89.20%  F1:  80.43%  #: 500

Final Score:
Calculating Precision: correct_by_relation= 2279.0 / guessed_by_relation= 3539.0
Calculating Recall: correct_by_relation= 2279.0 / gold_by_relation= 3325.0
only_non_relation: 3325.0
Precision (micro): 64.397%
   Recall (micro): 68.541%
       F1 (micro): 66.404%
Prediction scores saved to saved_models/out/test_6.pkl.
Evaluation ended.
(cuda2)

###### epoch 80 ##########
Final Score:
Calculating Precision: correct_by_relation= 2288.0 / guessed_by_relation= 3562.0
Calculating Recall: correct_by_relation= 2288.0 / gold_by_relation= 3325.0
only_non_relation: 3325.0
Precision (micro): 64.234%
   Recall (micro): 68.812%
       F1 (micro): 66.444%
Prediction scores saved to saved_models/out/test_6.pkl.
Evaluation ended.


########################################################################################
